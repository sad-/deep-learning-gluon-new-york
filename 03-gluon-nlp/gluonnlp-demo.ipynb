{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Word Embedding - Numerical representation for language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*\"You shall know a word by the company it keeps.\"* - John Rupert Firth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Tezgüino** <- What does this word mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A bottle of *Tezgüino* is on the table\n",
    "* *Tezgüino* makes you drunk\n",
    "* Everybody likes *Tezgüino*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How about now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Word2Vec\n",
    "\n",
    "FastText\n",
    "\n",
    "GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's see these in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonnlp in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluonnlp) (1.14.5)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: sacremoses in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.0.34)\n",
      "Requirement not upgraded as not directly required: tqdm in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from sacremoses) (4.36.1)\n",
      "Requirement not upgraded as not directly required: click in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from sacremoses) (6.7)\n",
      "Requirement not upgraded as not directly required: joblib in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from sacremoses) (0.13.2)\n",
      "Requirement not upgraded as not directly required: six in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from sacremoses) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonnlp\n",
    "!pip install -U sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import re\n",
    "import io\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0) if mx.test_utils.list_gpus() else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \" hello world \\n hello nice world \\n hi world \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need a tokenizer to process this string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def simple_tokenize(source_str, token_delim=' ', seq_delim='\\n'):\n",
    "    return filter(None, re.split(token_delim + '|' + seq_delim, source_str))\n",
    "counter = nlp.data.count_tokens(simple_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hello': 2, 'world': 3, 'nice': 1, 'hi': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vocab = nlp.Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<bos>', '<eos>', 'world', 'hello', 'hi', 'nice']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab.set_embedding(fasttext_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 300 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.39567   0.21454  -0.035389 -0.24299  -0.095645]\n",
       " [ 0.10444  -0.10858   0.27212   0.13299  -0.33165 ]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.embedding['hello', 'world'][:, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application of Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = nlp.embedding.create('glove', source='glove.6B.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = nlp.Vocab(nlp.data.Counter(embedding.idx_to_token))\n",
    "vocab.set_embedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71424\n",
      "beautiful\n"
     ]
    }
   ],
   "source": [
    "print(vocab['beautiful'])\n",
    "print(vocab.idx_to_token[71424])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Similarity\n",
    "\n",
    "![](support/cosinesimilarity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cos_sim(x, y):\n",
    "    return nd.dot(x, y) / (nd.norm(x) * nd.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def norm_vecs_by_row(x):\n",
    "    return x / nd.sqrt(nd.sum(x * x, axis=1)).reshape((-1,1))\n",
    "\n",
    "def get_knn(vocab, k, word):\n",
    "    word_vec = vocab.embedding[word].reshape((-1, 1))\n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs[4:], word_vec)\n",
    "    indices = nd.topk(dot_prod.squeeze(), k=k+1, ret_typ='indices')\n",
    "    indices = [int(i.asscalar())+4 for i in indices]\n",
    "    # Remove unknown and input tokens.\n",
    "    return vocab.to_tokens(indices[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['babies', 'boy', 'girl', 'newborn', 'pregnant']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 5, 'baby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can verify the cosine similarity of vectors of 'baby' and 'babies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.83871305]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vocab.embedding['baby'], vocab.embedding['babies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us find the 5 most similar words of 'beautiful' from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lovely', 'gorgeous', 'wonderful', 'charming', 'beauty']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(vocab, 5, 'beautiful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_k_by_analogy(vocab, k, word1, word2, word3):\n",
    "    word_vecs = vocab.embedding[word1, word2, word3]\n",
    "    \n",
    "    word_diff = (word_vecs[1] - word_vecs[0] + word_vecs[2])\n",
    "    \n",
    "    vocab_vecs = norm_vecs_by_row(vocab.embedding.idx_to_vec)\n",
    "    dot_prod = nd.dot(vocab_vecs[4:], word_diff.squeeze()).squeeze()\n",
    "    \n",
    "    indices = dot_prod.topk(k=k, ret_typ='indices')\n",
    "    indices = [int(i.asscalar())+4 for i in indices]\n",
    "    return vocab.to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daughter']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'man', 'woman', 'son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anelka', 'ribery', 'zidane']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 3, 'argentina', 'messi', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'argentina', 'football', 'india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quesadillas']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_k_by_analogy(vocab, 1, 'france', 'crepes', 'argentina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](support/elmo-embedding-robin-williams.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Context matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sentence Embeddings with Pretrained ELMo\n",
    "\n",
    "\n",
    "\n",
    "<img align=\"middle\" src=\"https://pbs.twimg.com/profile_images/1092451830758547457/EqQ6Csl3_400x400.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "elmo_intro = \"\"\"\n",
    "Extensive experiments demonstrate that ELMo representations work extremely well in practice.\n",
    "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n",
    "The addition of ELMo representations alone significantly improves the state of the art in every case, including up to 20% relative error reductions.\n",
    "For tasks where direct comparisons are possible, ELMo outperforms CoVe (McCann et al., 2017), which computes contextualized representations using a neural machine translation encoder.\n",
    "Finally, an analysis of both ELMo and CoVe reveals that deep representations outperform those derived from just the top layer of an LSTM.\n",
    "Our trained models and code are publicly available, and we expect that ELMo will provide similar gains for many other NLP problems.\n",
    "\"\"\"\n",
    "\n",
    "elmo_intro_file = 'elmo_intro.txt'\n",
    "with io.open(elmo_intro_file, 'w', encoding='utf8') as f:\n",
    "    f.write(elmo_intro)\n",
    "\n",
    "dataset = nlp.data.TextLineDataset(elmo_intro_file, 'utf8')\n",
    "print(len(dataset))\n",
    "print(dataset[2]) # print an example sentence from the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/data/transforms.py:183: UserWarning: NLTK or relevant packages are not installed. Due to the LGPL 2.1+, moses has been deprecated in NLTK since 3.3.0. You must install NLTK <= 3.2.5 in order to use the NLTKMosesTokenizer. You can refer to the official installation guide in https://www.nltk.org/install.html . Now try SacreMosesTokenizer using sacremoses ...\n",
      "  'NLTK or relevant packages are not installed. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'We', 'first', 'show', 'that', 'they', 'can', 'be', 'easily', 'added', 'to', 'existing', 'models', 'for', 'six', 'diverse', 'and', 'challenging', 'language', 'understanding', 'problems', ',', 'including', 'textual', 'entailment', ',', 'question', 'answering', 'and', 'sentiment', 'analysis', '.', '<eos>']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nlp.data.NLTKMosesTokenizer()\n",
    "dataset = dataset.transform(tokenizer)\n",
    "dataset = dataset.transform(lambda x: ['<bos>'] + x + ['<eos>'])\n",
    "print(dataset[2]) # print the same tokenized sentence as above\n",
    "print(len(dataset[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pretrained ELMo Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = nlp.vocab.ELMoCharVocab()\n",
    "dataset = dataset.transform(lambda x: (vocab[x], len(x)), lazy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/data/batchify/batchify.py:228: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dataset_batchify_fn = nlp.data.batchify.Tuple(nlp.data.batchify.Pad(),\n",
    "                                              nlp.data.batchify.Stack())\n",
    "data_loader = gluon.data.DataLoader(dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    batchify_fn=dataset_batchify_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load pretrained ELMo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "elmo_bilm, _ = nlp.model.get_model('elmo_2x1024_128_2048cnn_1xhighway',\n",
    "                                   dataset_name='gbw',\n",
    "                                   pretrained=True,\n",
    "                                   ctx=mx.cpu())\n",
    "#print(elmo_bilm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](support/elmo_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get sentence Features from Elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(data, valid_lengths):\n",
    "    length = data.shape[1]\n",
    "    hidden_state = elmo_bilm.begin_state(mx.nd.zeros, batch_size=batch_size)\n",
    "    mask = mx.nd.arange(length).expand_dims(0).broadcast_axes(axis=(0,), size=(batch_size,))\n",
    "    mask = mask < valid_lengths.expand_dims(1).astype('float32')\n",
    "    output, hidden_state = elmo_bilm(data, hidden_state, mask)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 14, 256), (2, 14, 256), (2, 14, 256)]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "features = get_features(*batch)\n",
    "print([x.shape for x in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finetuning BERT for sentence classification\n",
    "\n",
    "<img align=\"middle\" src=\"https://miro.medium.com/max/854/1*oUpWrMdvDWcWE_QSne-jOw.jpeg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get BERT base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                             dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                             use_decoder=False, use_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](support/bert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = [nlp.data.IMDB(root='data/imdb', segment=segment)\n",
    "                               for segment in ('train', 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Label processing Time=1.28s, #Sentences=25000\n",
      "Done! Label processing Time=1.29s, #Sentences=25000\n"
     ]
    }
   ],
   "source": [
    "def process_label(x):\n",
    "    data, label = x\n",
    "    # Label is a review score from 1 to 10. We take 6..10 as a positive sentiment\n",
    "    # and 1..5 as a negative\n",
    "    label = int(label > 5)\n",
    "    return [data, label]\n",
    "\n",
    "def process_dataset(dataset):\n",
    "    start = time.time()\n",
    "    with mp.Pool() as pool:\n",
    "        # Each sample is processed in an asynchronous manner.\n",
    "        dataset = gluon.data.SimpleDataset(pool.map(process_label, dataset))\n",
    "    end = time.time()\n",
    "    print('Done! Label processing Time={:.2f}s, #Sentences={}'.format(end - start, len(dataset)))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = process_dataset(train_dataset)\n",
    "test_dataset = process_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data preprocessing for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "class BERTDatasetTransform(object):\n",
    "    def __init__(self, tokenizer, max_seq_length, class_labels=None,\n",
    "                 label_alias=None, pad=True, pair=True, has_label=True):\n",
    "        self.class_labels = class_labels\n",
    "        self.has_label = has_label\n",
    "        self._label_dtype = 'int32' if class_labels else 'float32'\n",
    "        \n",
    "        if has_label and class_labels:\n",
    "            self._label_map = {}\n",
    "            for (i, label) in enumerate(class_labels):\n",
    "                self._label_map[label] = i\n",
    "            if label_alias:\n",
    "                for key in label_alias:\n",
    "                    self._label_map[key] = self._label_map[label_alias[key]]\n",
    "        \n",
    "        self._bert_xform = BERTSentenceTransform(\n",
    "            tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        if self.has_label:\n",
    "            input_ids, valid_length, segment_ids = self._bert_xform(line[:-1])\n",
    "            label = line[-1]\n",
    "            # map to int if class labels are available\n",
    "            if self.class_labels:\n",
    "                label = self._label_map[label]\n",
    "            label = np.array([label], dtype=self._label_dtype)\n",
    "            return input_ids, valid_length, segment_ids, label\n",
    "        else:\n",
    "            return self._bert_xform(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "\n",
    "# The maximum length of an input sequence\n",
    "max_len = 500\n",
    "\n",
    "# The labels for the two classes\n",
    "all_labels = [0, 1]\n",
    "\n",
    "transform = BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                 class_labels=all_labels,\n",
    "                                 has_label=True,\n",
    "                                 pad=True,\n",
    "                                 pair=False)\n",
    "\n",
    "data_train = train_dataset.transform(transform)\n",
    "data_test = test_dataset.transform(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = [    2  2023  3475  1005  1056  1996 21699  5863  3766  1010  4496]\n",
      "valid length = 270\n",
      "label = [1]\n"
     ]
    }
   ],
   "source": [
    "sample_id = 5\n",
    "print(vocabulary)\n",
    "print('%s token id = %s' % (vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s' % (vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s' % (vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "print('token ids = %s' % data_train[sample_id][0][:11])\n",
    "print('valid length = %s' % data_train[sample_id][1])\n",
    "print('label = %s' % data_train[sample_id][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier Model using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(gluon.nn.Block):\n",
    "    def __init__(self, bert, num_classes=2, dropout=0.0, prefix=None, params=None):\n",
    "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.classifier = gluon.nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(gluon.nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(gluon.nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):\n",
    "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
    "        return self.classifier(pooler_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# only need to initialize the classifier layer.\n",
    "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "#bert_classifier.hybridize(static_alloc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss, Trainer, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "lr = 5e-6\n",
    "log_interval = 300\n",
    "num_epochs = 1\n",
    "grad_clip = 1\n",
    "\n",
    "loss_function = mx.gluon.loss.SoftmaxCELoss()\n",
    "trainer = mx.gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': lr, 'epsilon': 1e-9})\n",
    "\n",
    "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "def evaluate(model, dataloader, context):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    step_loss = 0\n",
    "    \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(dataloader):\n",
    "        token_ids = token_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "        segment_ids = segment_ids.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "\n",
    "        out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        ls = loss_function(out, label).mean()\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "\n",
    "    return metric.get()[1], step_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, ctx, num_epochs):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    # Collect all differentiable parameters for gradient clipping\n",
    "    params = [p for p in model.collect_params().values() if p.grad_req != 'null']\n",
    "\n",
    "    for epoch_id in range(num_epochs):\n",
    "        metric.reset()\n",
    "        step_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            with mx.autograd.record():\n",
    "                out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "                ls = loss_function(out, label).mean()\n",
    "\n",
    "            ls.backward()\n",
    "\n",
    "            trainer.allreduce_grads()\n",
    "            nlp.utils.clip_grad_global_norm(params, 1)\n",
    "            trainer.update(1)\n",
    "\n",
    "            step_loss += ls.asscalar()\n",
    "            metric.update([label], [out])\n",
    "\n",
    "            if (batch_id + 1) % (log_interval) == 0:\n",
    "                print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                             .format(epoch_id, batch_id + 1, len(train_dataloader),\n",
    "                                     step_loss / log_interval, trainer.learning_rate, metric.get()[1]))\n",
    "                step_loss = 0\n",
    "        \n",
    "        test_acc, test_loss = evaluate(model, test_dataloader, ctx)\n",
    "        print('[Epoch {}] test_loss={:.4f}, test_acc={:.3f}'\n",
    "             .format(epoch_id, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 300/2500] loss=0.5143, lr=0.0000050, acc=0.740\n",
      "[Epoch 0 Batch 600/2500] loss=0.3015, lr=0.0000050, acc=0.812\n",
      "[Epoch 0 Batch 900/2500] loss=0.2713, lr=0.0000050, acc=0.841\n",
      "[Epoch 0 Batch 1200/2500] loss=0.2732, lr=0.0000050, acc=0.858\n",
      "[Epoch 0 Batch 1500/2500] loss=0.2462, lr=0.0000050, acc=0.870\n",
      "[Epoch 0 Batch 1800/2500] loss=0.2642, lr=0.0000050, acc=0.877\n",
      "[Epoch 0 Batch 2100/2500] loss=0.2795, lr=0.0000050, acc=0.881\n",
      "[Epoch 0 Batch 2400/2500] loss=0.2381, lr=0.0000050, acc=0.886\n",
      "[Epoch 0] test_loss=0.2123, test_acc=0.926\n"
     ]
    }
   ],
   "source": [
    "train(model, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test with example reveiw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "review_text = 'I would like to say something positive about this movie, and I can\\'t'\n",
    "review_transformed = transform((review_text, 0))\n",
    "\n",
    "token_ids =  mx.nd.array(review_transformed[0], ctx=ctx).reshape(1, -1)\n",
    "segment_ids =  mx.nd.array(review_transformed[2], ctx=ctx).reshape(1, -1)\n",
    "valid_length = mx.nd.array(review_transformed[1], ctx=ctx).reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I would like to say something positive about this movie, and I can't\" is 5.7% likely to be positive\n"
     ]
    }
   ],
   "source": [
    "positive_review_probability = model(token_ids, segment_ids, valid_length.astype('float32')).softmax()\n",
    "print('\"{}\" is {:.1f}% likely to be positive'.format(\n",
    "    review_text,\n",
    "    100 * positive_review_probability[0][1].asscalar()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
